{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Correct color of the STL-10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "stqcBP1Pb28z"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import color\n",
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from torchvision.io import read_image\n",
        "from skimage.io import imread\n",
        "import threading\n",
        "import time\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QiViQ0FbdKC"
      },
      "source": [
        "# Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ASZ3s5Vzaq3O"
      },
      "outputs": [],
      "source": [
        "def calc_deltaE(source, target, color_chart_area):\n",
        "  source = cv2.cvtColor(source, cv2.COLOR_BGR2RGB)\n",
        "  target = cv2.cvtColor(target, cv2.COLOR_BGR2RGB)\n",
        "  source = color.rgb2lab(source)\n",
        "  target = color.rgb2lab(target)\n",
        "  source = np.reshape(source, [-1, 3]).astype(np.float32)\n",
        "  target = np.reshape(target, [-1, 3]).astype(np.float32)\n",
        "  delta_e = np.sqrt(np.sum(np.power(source - target, 2), 1))\n",
        "  return sum(delta_e) / (np.shape(delta_e)[0] - color_chart_area)\n",
        "\n",
        "def calc_deltaE2000(source, target, color_chart_area):\n",
        "  source = cv2.cvtColor(source, cv2.COLOR_BGR2RGB)\n",
        "  target = cv2.cvtColor(target, cv2.COLOR_BGR2RGB)\n",
        "  source = color.rgb2lab(source)\n",
        "  target = color.rgb2lab(target)\n",
        "  source = np.reshape(source, [-1, 3]).astype(np.float32)\n",
        "  target = np.reshape(target, [-1, 3]).astype(np.float32)\n",
        "  deltaE00 = deltaE2000(source, target)\n",
        "  return sum(deltaE00) / (np.shape(deltaE00)[0] - color_chart_area)\n",
        "\n",
        "\n",
        "def deltaE2000(Labstd, Labsample):\n",
        "  kl = 1\n",
        "  kc = 1\n",
        "  kh = 1\n",
        "  Lstd = np.transpose(Labstd[:, 0])\n",
        "  astd = np.transpose(Labstd[:, 1])\n",
        "  bstd = np.transpose(Labstd[:, 2])\n",
        "  Cabstd = np.sqrt(np.power(astd, 2) + np.power(bstd, 2))\n",
        "  Lsample = np.transpose(Labsample[:, 0])\n",
        "  asample = np.transpose(Labsample[:, 1])\n",
        "  bsample = np.transpose(Labsample[:, 2])\n",
        "  Cabsample = np.sqrt(np.power(asample, 2) + np.power(bsample, 2))\n",
        "  Cabarithmean = (Cabstd + Cabsample) / 2\n",
        "  G = 0.5 * (1 - np.sqrt((np.power(Cabarithmean, 7)) / (np.power(\n",
        "    Cabarithmean, 7) + np.power(25, 7))))\n",
        "  apstd = (1 + G) * astd\n",
        "  apsample = (1 + G) * asample\n",
        "  Cpsample = np.sqrt(np.power(apsample, 2) + np.power(bsample, 2))\n",
        "  Cpstd = np.sqrt(np.power(apstd, 2) + np.power(bstd, 2))\n",
        "  Cpprod = (Cpsample * Cpstd)\n",
        "  zcidx = np.argwhere(Cpprod == 0)\n",
        "  hpstd = np.arctan2(bstd, apstd)\n",
        "  hpstd[np.argwhere((np.abs(apstd) + np.abs(bstd)) == 0)] = 0\n",
        "  hpsample = np.arctan2(bsample, apsample)\n",
        "  hpsample = hpsample + 2 * np.pi * (hpsample < 0)\n",
        "  hpsample[np.argwhere((np.abs(apsample) + np.abs(bsample)) == 0)] = 0\n",
        "  dL = (Lsample - Lstd)\n",
        "  dC = (Cpsample - Cpstd)\n",
        "  dhp = (hpsample - hpstd)\n",
        "  dhp = dhp - 2 * np.pi * (dhp > np.pi)\n",
        "  dhp = dhp + 2 * np.pi * (dhp < (-np.pi))\n",
        "  dhp[zcidx] = 0\n",
        "  dH = 2 * np.sqrt(Cpprod) * np.sin(dhp / 2)\n",
        "  Lp = (Lsample + Lstd) / 2\n",
        "  Cp = (Cpstd + Cpsample) / 2\n",
        "  hp = (hpstd + hpsample) / 2\n",
        "  hp = hp - (np.abs(hpstd - hpsample) > np.pi) * np.pi\n",
        "  hp = hp + (hp < 0) * 2 * np.pi\n",
        "  hp[zcidx] = hpsample[zcidx] + hpstd[zcidx]\n",
        "  Lpm502 = np.power((Lp - 50), 2)\n",
        "  Sl = 1 + 0.015 * Lpm502 / np.sqrt(20 + Lpm502)\n",
        "  Sc = 1 + 0.045 * Cp\n",
        "  T = 1 - 0.17 * np.cos(hp - np.pi / 6) + 0.24 * np.cos(2 * hp) + \\\n",
        "      0.32 * np.cos(3 * hp + np.pi / 30) \\\n",
        "      - 0.20 * np.cos(4 * hp - 63 * np.pi / 180)\n",
        "  Sh = 1 + 0.015 * Cp * T\n",
        "  delthetarad = (30 * np.pi / 180) * np.exp(\n",
        "    - np.power((180 / np.pi * hp - 275) / 25, 2))\n",
        "  Rc = 2 * np.sqrt((np.power(Cp, 7)) / (np.power(Cp, 7) + np.power(25, 7)))\n",
        "  RT = - np.sin(2 * delthetarad) * Rc\n",
        "  klSl = kl * Sl\n",
        "  kcSc = kc * Sc\n",
        "  khSh = kh * Sh\n",
        "  de00 = np.sqrt(np.power((dL / klSl), 2) + np.power((dC / kcSc), 2) +\n",
        "                 np.power((dH / khSh), 2) + RT * (dC / kcSc) * (dH / khSh))\n",
        "  return de00\n",
        "\n",
        "\n",
        "def calc_mae(source, target, color_chart_area):\n",
        "  source = np.reshape(source, [-1, 3]).astype(np.float32)\n",
        "  target = np.reshape(target, [-1, 3]).astype(np.float32)\n",
        "  source_norm = np.sqrt(np.sum(np.power(source, 2), 1))\n",
        "  target_norm = np.sqrt(np.sum(np.power(target, 2), 1))\n",
        "  norm = source_norm * target_norm\n",
        "  L = np.shape(norm)[0]\n",
        "  inds = norm != 0\n",
        "  angles = np.sum(source[inds, :] * target[inds, :], 1) / norm[inds]\n",
        "  angles[angles > 1] = 1\n",
        "  f = np.arccos(angles)\n",
        "  f[np.isnan(f)] = 0\n",
        "  f = f * 180 / np.pi\n",
        "  return sum(f) / (L - color_chart_area)\n",
        "\n",
        "\n",
        "\n",
        "def calc_mse(source, target, color_chart_area):\n",
        "  source = np.reshape(source, [-1, 1]).astype(np.float64)\n",
        "  target = np.reshape(target, [-1, 1]).astype(np.float64)\n",
        "  mse = sum(np.power((source - target), 2))\n",
        "  return mse / ((np.shape(source)[\n",
        "    0]) - color_chart_area)\n",
        "\n",
        "\n",
        "def evaluate_cc(corrected, gt, color_chart_area, opt=1):\n",
        "  \"\"\"\n",
        "    Color constancy (white-balance correction) evaluation of a given corrected\n",
        "    image.\n",
        "    :param corrected: corrected image\n",
        "    :param gt: ground-truth image\n",
        "    :param color_chart_area: If there is a color chart in the image, that is\n",
        "     masked out from both images, this variable represents the number of pixels\n",
        "     of the color chart.\n",
        "    :param opt: determines the required error metric(s) to be reported.\n",
        "         Options:\n",
        "           opt = 1 delta E 2000 (default).\n",
        "           opt = 2 delta E 2000 and mean squared error (MSE)\n",
        "           opt = 3 delta E 2000, MSE, and mean angular eror (MAE)\n",
        "           opt = 4 delta E 2000, MSE, MAE, and delta E 76\n",
        "    :return: error(s) between corrected and gt images\n",
        "    \"\"\"\n",
        "\n",
        "  if opt == 1:\n",
        "    return calc_deltaE2000(corrected, gt, color_chart_area)\n",
        "  elif opt == 2:\n",
        "    return calc_deltaE2000(corrected, gt, color_chart_area), calc_mse(\n",
        "      corrected, gt, color_chart_area)\n",
        "  elif opt == 3:\n",
        "    return calc_deltaE2000(corrected, gt, color_chart_area), calc_mse(\n",
        "      corrected, gt, color_chart_area), calc_mae(corrected, gt,\n",
        "                                                 color_chart_area)\n",
        "  elif opt == 4:\n",
        "    return calc_deltaE2000(corrected, gt, color_chart_area), calc_mse(\n",
        "      corrected, gt, color_chart_area), calc_mae(\n",
        "      corrected, gt, color_chart_area), calc_deltaE(corrected, gt,\n",
        "                                                    color_chart_area)\n",
        "  else:\n",
        "    raise Exception('Error in evaluate_cc function')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_metadata(fileName, set, metadata_baseDir=''):\n",
        "    \"\"\"\n",
        "    Gets metadata (e.g., ground-truth file name, chart coordinates and area).\n",
        "    :param fileName: input filename\n",
        "    :param set: which dataset?--options includes: 'RenderedWB_Set1',\n",
        "      'RenderedWB_Set2', 'Rendered_Cube+'\n",
        "    :param metadata_baseDir: metadata directory (required for Set1 only)\n",
        "    :return: metadata for a given image\n",
        "    evaluation_examples.py provides some examples of how to use it\n",
        "    \"\"\"\n",
        "\n",
        "    fname, file_extension = os.path.splitext(fileName)  # get file parts\n",
        "    name = os.path.basename(fname)  # get only filename without the directory\n",
        "\n",
        "    if set == 'RenderedWB_Set1': # Rendered WB dataset (Set1)\n",
        "        metadatafile_color = name + '_color.txt' # chart's colors info.\n",
        "        metadatafile_mask = name + '_mask.txt' # chart's coordinate info.\n",
        "        # get color info.\n",
        "        f = open(os.path.join(metadata_baseDir, metadatafile_color), 'r')\n",
        "        C = f.read()\n",
        "        colors = np.zeros((3, 24))  # color chart colors\n",
        "        temp = re.split(',|\\n', C)\n",
        "        # 3 x 24 colors in the color chart\n",
        "        colors = np.reshape(np.asfarray(temp[:-1], float), (24, 3)).transpose()\n",
        "        # get coordinate info\n",
        "        f = open(os.path.join(metadata_baseDir, metadatafile_mask), 'r')\n",
        "        C = f.read()\n",
        "        temp = re.split(',|\\n', C)\n",
        "        # take only the first 4 elements (i.e., the color chart coordinates)\n",
        "        temp = temp[0:4]\n",
        "        mask = np.asfarray(temp, float)  # color chart mask coordinates\n",
        "        # get ground-truth file name\n",
        "        seperator = '_'\n",
        "        temp = name.split(seperator)\n",
        "        gt_file = seperator.join(temp[:-2])\n",
        "        gt_file = gt_file + '_G_AS.png'\n",
        "        # compute mask area\n",
        "        mask_area = mask[2] * mask[3]\n",
        "        # final metadata\n",
        "        data = {\"gt_filename\": gt_file, \"cc_colors\": colors, \"cc_mask\": mask,\n",
        "                \"cc_mask_area\": mask_area}\n",
        "\n",
        "    elif set == 'RenderedWB_Set2': # Rendered WB dataset (Set2)\n",
        "        data = {\"gt_filename\": name + file_extension, \"cc_colors\": None,\n",
        "                \"cc_mask\": None, \"cc_mask_area\": 0}\n",
        "\n",
        "    elif set == 'Rendered_Cube+': # Rendered Cube+\n",
        "        # get ground-truth filename\n",
        "        temp = name.split('_')\n",
        "        gt_file = temp[0] + file_extension\n",
        "        mask_area = 58373  # calibration obj's area is fixed over all images\n",
        "        data = {\"gt_filename\": gt_file, \"cc_colors\": None, \"cc_mask\": None,\n",
        "                \"cc_mask_area\": mask_area}\n",
        "    else:\n",
        "        raise Exception(\n",
        "            \"Invalid value for set variable. \" +\n",
        "            \"Please use: 'RenderedWB_Set1', 'RenderedWB_Set2', 'Rendered_Cube+'\")\n",
        "\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nz4lbyHbn_p"
      },
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iAaxGk-7bYjx"
      },
      "outputs": [],
      "source": [
        "CHECKPOINTS = './checkpoints/'\n",
        "IN_DIR = '/content/Set1_input_images_wo_CC_JPG'\n",
        "GT_DIR = '/content/Set1_ground_truth_images_wo_CC'\n",
        "FOLD_DIR = '/content/drive/MyDrive/CC/datasets/Set1_folds'\n",
        "METADATA_DIR = '/content/Set1_input_images_metadata'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI71lUwEIGtI"
      },
      "source": [
        "# Attention U-Net model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8b_yn1fPIJt0"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "\n",
        "        # number of input channels is a number of filters in the previous layer\n",
        "        # number of output channels is a number of filters in the current layer\n",
        "        # \"same\" convolutions\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UpConv(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UpConv, self).__init__()\n",
        "\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.up(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    \"\"\"Attention block with learnable parameters\"\"\"\n",
        "\n",
        "    def __init__(self, F_g, F_l, n_coefficients):\n",
        "        \"\"\"\n",
        "        :param F_g: number of feature maps (channels) in previous layer\n",
        "        :param F_l: number of feature maps in corresponding encoder layer, transferred via skip connection\n",
        "        :param n_coefficients: number of learnable multi-dimensional attention coefficients\n",
        "        \"\"\"\n",
        "        super(AttentionBlock, self).__init__()\n",
        "\n",
        "        self.W_gate = nn.Sequential(\n",
        "            nn.Conv2d(F_g, n_coefficients, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(n_coefficients)\n",
        "        )\n",
        "\n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, n_coefficients, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(n_coefficients)\n",
        "        )\n",
        "\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(n_coefficients, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, gate, skip_connection):\n",
        "        \"\"\"\n",
        "        :param gate: gating signal from previous layer\n",
        "        :param skip_connection: activation from corresponding encoder layer\n",
        "        :return: output activations\n",
        "        \"\"\"\n",
        "        g1 = self.W_gate(gate)\n",
        "        x1 = self.W_x(skip_connection)\n",
        "        psi = self.relu(g1 + x1)\n",
        "        psi = self.psi(psi)\n",
        "        out = skip_connection * psi\n",
        "        return out\n",
        "\n",
        "\n",
        "class AttentionUNet(nn.Module):\n",
        "\n",
        "    def __init__(self, img_ch=3, output_ch=3):\n",
        "        super(AttentionUNet, self).__init__()\n",
        "\n",
        "        self.MaxPool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.Conv1 = ConvBlock(img_ch, 24)\n",
        "        self.Conv2 = ConvBlock(24, 48)\n",
        "        self.Conv3 = ConvBlock(48, 96)\n",
        "        self.Conv4 = ConvBlock(96, 192)\n",
        "        self.Conv5 = ConvBlock(192, 384)\n",
        "\n",
        "        self.Up5 = UpConv(384, 192)\n",
        "        self.Att5 = AttentionBlock(F_g=192, F_l=192, n_coefficients=96)\n",
        "        self.UpConv5 = ConvBlock(384, 192)\n",
        "\n",
        "        self.Up4 = UpConv(192, 96)\n",
        "        self.Att4 = AttentionBlock(F_g=96, F_l=96, n_coefficients=48)\n",
        "        self.UpConv4 = ConvBlock(192, 96)\n",
        "\n",
        "        self.Up3 = UpConv(96, 48)\n",
        "        self.Att3 = AttentionBlock(F_g=48, F_l=48, n_coefficients=24)\n",
        "        self.UpConv3 = ConvBlock(96, 48)\n",
        "\n",
        "        self.Up2 = UpConv(48, 24)\n",
        "        self.Att2 = AttentionBlock(F_g=24, F_l=24, n_coefficients=12)\n",
        "        self.UpConv2 = ConvBlock(48, 24)\n",
        "\n",
        "        self.Conv = nn.Conv2d(24, output_ch, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        e : encoder layers\n",
        "        d : decoder layers\n",
        "        s : skip-connections from encoder layers to decoder layers\n",
        "        \"\"\"\n",
        "        e1 = self.Conv1(x)\n",
        "\n",
        "        e2 = self.MaxPool(e1)\n",
        "        e2 = self.Conv2(e2)\n",
        "\n",
        "        e3 = self.MaxPool(e2)\n",
        "        e3 = self.Conv3(e3)\n",
        "\n",
        "        e4 = self.MaxPool(e3)\n",
        "        e4 = self.Conv4(e4)\n",
        "\n",
        "        e5 = self.MaxPool(e4)\n",
        "        e5 = self.Conv5(e5)\n",
        "\n",
        "        d5 = self.Up5(e5)\n",
        "\n",
        "        s4 = self.Att5(gate=d5, skip_connection=e4)\n",
        "        d5 = torch.cat((s4, d5), dim=1) # concatenate attention-weighted skip connection with previous layer output\n",
        "        d5 = self.UpConv5(d5)\n",
        "\n",
        "        d4 = self.Up4(d5)\n",
        "        s3 = self.Att4(gate=d4, skip_connection=e3)\n",
        "        d4 = torch.cat((s3, d4), dim=1)\n",
        "        d4 = self.UpConv4(d4)\n",
        "\n",
        "        d3 = self.Up3(d4)\n",
        "        s2 = self.Att3(gate=d3, skip_connection=e2)\n",
        "        d3 = torch.cat((s2, d3), dim=1)\n",
        "        d3 = self.UpConv3(d3)\n",
        "\n",
        "        d2 = self.Up2(d3)\n",
        "        s1 = self.Att2(gate=d2, skip_connection=e1)\n",
        "        d2 = torch.cat((s1, d2), dim=1)\n",
        "        d2 = self.UpConv2(d2)\n",
        "\n",
        "        out = self.Conv(d2)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkif8gdZghz6"
      },
      "source": [
        "# Inference model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DENaRa90W9h1"
      },
      "source": [
        "## Post process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7tTx1rmhgkVp"
      },
      "outputs": [],
      "source": [
        "def kernelP(I):\n",
        "    \"\"\" Kernel function: kernel(r, g, b) -> (r,g,b,rg,rb,gb,r^2,g^2,b^2,rgb,1)\n",
        "        Ref: Hong, et al., \"A study of digital camera colorimetric characterization\n",
        "         based on polynomial modeling.\" Color Research & Application, 2001. \"\"\"\n",
        "    return (np.transpose((I[:, 0], I[:, 1], I[:, 2], I[:, 0] * I[:, 1], I[:, 0] * I[:, 2],\n",
        "                          I[:, 1] * I[:, 2], I[:, 0] * I[:, 0], I[:, 1] * I[:, 1],\n",
        "                          I[:, 2] * I[:, 2], I[:, 0] * I[:, 1] * I[:, 2],\n",
        "                          np.repeat(1, np.shape(I)[0]))))\n",
        "\n",
        "\n",
        "def get_mapping_func(image1, image2):\n",
        "    \"\"\" Computes the polynomial mapping \"\"\"\n",
        "    image1 = np.reshape(image1, [-1, 3])\n",
        "    image2 = np.reshape(image2, [-1, 3])\n",
        "    m = LinearRegression().fit(kernelP(image1), image2)\n",
        "    return m\n",
        "\n",
        "\n",
        "def apply_mapping_func(image, m):\n",
        "    \"\"\" Applies the polynomial mapping \"\"\"\n",
        "    sz = image.shape\n",
        "    image = np.reshape(image, [-1, 3])\n",
        "    result = m.predict(kernelP(image))\n",
        "    result = np.reshape(result, [sz[0], sz[1], sz[2]])\n",
        "    return result\n",
        "\n",
        "def outOfGamutClipping(I):\n",
        "    \"\"\" Clips out-of-gamut pixels. \"\"\"\n",
        "    I[I > 1] = 1  # any pixel is higher than 1, clip it to 1\n",
        "    I[I < 0] = 0  # any pixel is below 0, clip it to 0\n",
        "    return I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTjUvwJlXGQ_"
      },
      "source": [
        "## DL model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "20F2M9fYgnWB"
      },
      "outputs": [],
      "source": [
        "mytransform = transforms.Compose([\n",
        "    transforms.Resize((256, 256))\n",
        "])\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "model_checkpoint_path = os.path.join(CHECKPOINTS, 'a-unet_aug_20220918_104239_done.pth')\n",
        "net = AttentionUNet()\n",
        "net.load_state_dict(torch.load(model_checkpoint_path))\n",
        "net.eval()\n",
        "net = net.to(device)\n",
        "\n",
        "\n",
        "def infer(image):\n",
        "    \"\"\"image: float np array RGB image\"\"\"\n",
        "    with torch.no_grad():\n",
        "        input = torch.from_numpy(image)\n",
        "        input = input.permute((2,0,1))\n",
        "        input = mytransform(input)\n",
        "        image1 = input.permute((1,2,0)).numpy()\n",
        "        input = input.to(torch.float32)\n",
        "        input = input.unsqueeze(0)\n",
        "        output = net(input.to(device))[0]\n",
        "    output = output.permute((1,2,0)).cpu().numpy()\n",
        "    mapping_func = get_mapping_func(image1, output)\n",
        "    return outOfGamutClipping(apply_mapping_func(image, mapping_func))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Correct images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sys.version_info(major=3, minor=9, micro=7, releaselevel='final', serial=0)\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import sys\n",
        "import os, sys, tarfile, errno\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "    \n",
        "if sys.version_info >= (3, 0, 0):\n",
        "    import urllib.request as urllib # ugly but works\n",
        "else:\n",
        "    import urllib\n",
        "\n",
        "try:\n",
        "    from imageio import imsave\n",
        "except:\n",
        "    from scipy.misc import imsave\n",
        "\n",
        "print(sys.version_info) \n",
        "\n",
        "# image shape\n",
        "HEIGHT = 96\n",
        "WIDTH = 96\n",
        "DEPTH = 3\n",
        "\n",
        "# size of a single image in bytes\n",
        "SIZE = HEIGHT * WIDTH * DEPTH\n",
        "\n",
        "# path to the directory with the data\n",
        "DATA_DIR = './data'\n",
        "\n",
        "# url of the binary data\n",
        "DATA_URL = 'http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz'\n",
        "\n",
        "# path to the binary train file with image data\n",
        "DATA_PATH = './data/stl10_binary/train_X.bin'\n",
        "\n",
        "# path to the binary train file with labels\n",
        "LABEL_PATH = './data/stl10_binary/train_y.bin'\n",
        "\n",
        "def read_labels(path_to_labels):\n",
        "    \"\"\"\n",
        "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
        "    :return: an array containing the labels\n",
        "    \"\"\"\n",
        "    with open(path_to_labels, 'rb') as f:\n",
        "        labels = np.fromfile(f, dtype=np.uint8)\n",
        "        return labels\n",
        "\n",
        "\n",
        "def read_all_images(path_to_data):\n",
        "    \"\"\"\n",
        "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
        "    :return: an array containing all the images\n",
        "    \"\"\"\n",
        "\n",
        "    with open(path_to_data, 'rb') as f:\n",
        "        # read whole file in uint8 chunks\n",
        "        everything = np.fromfile(f, dtype=np.uint8)\n",
        "\n",
        "        # We force the data into 3x96x96 chunks, since the\n",
        "        # images are stored in \"column-major order\", meaning\n",
        "        # that \"the first 96*96 values are the red channel,\n",
        "        # the next 96*96 are green, and the last are blue.\"\n",
        "        # The -1 is since the size of the pictures depends\n",
        "        # on the input file, and this way numpy determines\n",
        "        # the size on its own.\n",
        "\n",
        "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
        "\n",
        "        # Now transpose the images into a standard image format\n",
        "        # readable by, for example, matplotlib.imshow\n",
        "        # You might want to comment this line or reverse the shuffle\n",
        "        # if you will use a learning algorithm like CNN, since they like\n",
        "        # their channels separated.\n",
        "        images = np.transpose(images, (0, 3, 2, 1))\n",
        "        return images\n",
        "\n",
        "\n",
        "def read_single_image(image_file):\n",
        "    \"\"\"\n",
        "    CAREFUL! - this method uses a file as input instead of the path - so the\n",
        "    position of the reader will be remembered outside of context of this method.\n",
        "    :param image_file: the open file containing the images\n",
        "    :return: a single image\n",
        "    \"\"\"\n",
        "    # read a single image, count determines the number of uint8's to read\n",
        "    image = np.fromfile(image_file, dtype=np.uint8, count=SIZE)\n",
        "    # force into image matrix\n",
        "    image = np.reshape(image, (3, 96, 96))\n",
        "    # transpose to standard format\n",
        "    # You might want to comment this line or reverse the shuffle\n",
        "    # if you will use a learning algorithm like CNN, since they like\n",
        "    # their channels separated.\n",
        "    image = np.transpose(image, (2, 1, 0))\n",
        "    return image\n",
        "\n",
        "\n",
        "def plot_image(image):\n",
        "    \"\"\"\n",
        "    :param image: the image to be plotted in a 3-D matrix format\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "def save_image(image, name):\n",
        "    imsave(\"%s.png\" % name, image, format=\"png\")\n",
        "\n",
        "\n",
        "def save_images(images, labels):\n",
        "    print(\"Saving images to disk\")\n",
        "    i = 0\n",
        "    for image in images:\n",
        "        label = labels[i]\n",
        "        directory = './img/' + str(label) + '/'\n",
        "        try:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "        except OSError as exc:\n",
        "            if exc.errno == errno.EEXIST:\n",
        "                pass\n",
        "        filename = directory + str(i)\n",
        "        # print(filename)\n",
        "        image = (infer(image / 255) * 255).astype(\"uint8\")\n",
        "        save_image(image, filename)\n",
        "        i = i+1\n",
        "        if i % 10 == 9:\n",
        "            print(f'[{i+1}/{len(images)}]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5000, 96, 96, 3)\n",
            "(5000,)\n",
            "Saving images to disk\n",
            "[10/5000]\n",
            "[20/5000]\n",
            "[30/5000]\n",
            "[40/5000]\n",
            "[50/5000]\n",
            "[60/5000]\n",
            "[70/5000]\n",
            "[80/5000]\n",
            "[90/5000]\n",
            "[100/5000]\n",
            "[110/5000]\n",
            "[120/5000]\n",
            "[130/5000]\n",
            "[140/5000]\n",
            "[150/5000]\n",
            "[160/5000]\n",
            "[170/5000]\n",
            "[180/5000]\n",
            "[190/5000]\n",
            "[200/5000]\n",
            "[210/5000]\n",
            "[220/5000]\n",
            "[230/5000]\n",
            "[240/5000]\n",
            "[250/5000]\n",
            "[260/5000]\n",
            "[270/5000]\n",
            "[280/5000]\n",
            "[290/5000]\n",
            "[300/5000]\n",
            "[310/5000]\n",
            "[320/5000]\n",
            "[330/5000]\n",
            "[340/5000]\n",
            "[350/5000]\n",
            "[360/5000]\n",
            "[370/5000]\n",
            "[380/5000]\n",
            "[390/5000]\n",
            "[400/5000]\n",
            "[410/5000]\n",
            "[420/5000]\n",
            "[430/5000]\n",
            "[440/5000]\n",
            "[450/5000]\n",
            "[460/5000]\n",
            "[470/5000]\n",
            "[480/5000]\n",
            "[490/5000]\n",
            "[500/5000]\n",
            "[510/5000]\n",
            "[520/5000]\n",
            "[530/5000]\n",
            "[540/5000]\n",
            "[550/5000]\n",
            "[560/5000]\n",
            "[570/5000]\n",
            "[580/5000]\n",
            "[590/5000]\n",
            "[600/5000]\n",
            "[610/5000]\n",
            "[620/5000]\n",
            "[630/5000]\n",
            "[640/5000]\n",
            "[650/5000]\n",
            "[660/5000]\n",
            "[670/5000]\n",
            "[680/5000]\n",
            "[690/5000]\n",
            "[700/5000]\n",
            "[710/5000]\n",
            "[720/5000]\n",
            "[730/5000]\n",
            "[740/5000]\n",
            "[750/5000]\n",
            "[760/5000]\n",
            "[770/5000]\n",
            "[780/5000]\n",
            "[790/5000]\n",
            "[800/5000]\n",
            "[810/5000]\n",
            "[820/5000]\n",
            "[830/5000]\n",
            "[840/5000]\n",
            "[850/5000]\n",
            "[860/5000]\n",
            "[870/5000]\n",
            "[880/5000]\n",
            "[890/5000]\n",
            "[900/5000]\n",
            "[910/5000]\n",
            "[920/5000]\n",
            "[930/5000]\n",
            "[940/5000]\n",
            "[950/5000]\n",
            "[960/5000]\n",
            "[970/5000]\n",
            "[980/5000]\n",
            "[990/5000]\n",
            "[1000/5000]\n",
            "[1010/5000]\n",
            "[1020/5000]\n",
            "[1030/5000]\n",
            "[1040/5000]\n",
            "[1050/5000]\n",
            "[1060/5000]\n",
            "[1070/5000]\n",
            "[1080/5000]\n",
            "[1090/5000]\n",
            "[1100/5000]\n",
            "[1110/5000]\n",
            "[1120/5000]\n",
            "[1130/5000]\n",
            "[1140/5000]\n",
            "[1150/5000]\n",
            "[1160/5000]\n",
            "[1170/5000]\n",
            "[1180/5000]\n",
            "[1190/5000]\n",
            "[1200/5000]\n",
            "[1210/5000]\n",
            "[1220/5000]\n",
            "[1230/5000]\n",
            "[1240/5000]\n",
            "[1250/5000]\n",
            "[1260/5000]\n",
            "[1270/5000]\n",
            "[1280/5000]\n",
            "[1290/5000]\n",
            "[1300/5000]\n",
            "[1310/5000]\n",
            "[1320/5000]\n",
            "[1330/5000]\n",
            "[1340/5000]\n",
            "[1350/5000]\n",
            "[1360/5000]\n",
            "[1370/5000]\n",
            "[1380/5000]\n",
            "[1390/5000]\n",
            "[1400/5000]\n",
            "[1410/5000]\n",
            "[1420/5000]\n",
            "[1430/5000]\n",
            "[1440/5000]\n",
            "[1450/5000]\n",
            "[1460/5000]\n",
            "[1470/5000]\n",
            "[1480/5000]\n",
            "[1490/5000]\n",
            "[1500/5000]\n",
            "[1510/5000]\n",
            "[1520/5000]\n",
            "[1530/5000]\n",
            "[1540/5000]\n",
            "[1550/5000]\n",
            "[1560/5000]\n",
            "[1570/5000]\n",
            "[1580/5000]\n",
            "[1590/5000]\n",
            "[1600/5000]\n",
            "[1610/5000]\n",
            "[1620/5000]\n",
            "[1630/5000]\n",
            "[1640/5000]\n",
            "[1650/5000]\n",
            "[1660/5000]\n",
            "[1670/5000]\n",
            "[1680/5000]\n",
            "[1690/5000]\n",
            "[1700/5000]\n",
            "[1710/5000]\n",
            "[1720/5000]\n",
            "[1730/5000]\n",
            "[1740/5000]\n",
            "[1750/5000]\n",
            "[1760/5000]\n",
            "[1770/5000]\n",
            "[1780/5000]\n",
            "[1790/5000]\n",
            "[1800/5000]\n",
            "[1810/5000]\n",
            "[1820/5000]\n",
            "[1830/5000]\n",
            "[1840/5000]\n",
            "[1850/5000]\n",
            "[1860/5000]\n",
            "[1870/5000]\n",
            "[1880/5000]\n",
            "[1890/5000]\n",
            "[1900/5000]\n",
            "[1910/5000]\n",
            "[1920/5000]\n",
            "[1930/5000]\n",
            "[1940/5000]\n",
            "[1950/5000]\n",
            "[1960/5000]\n",
            "[1970/5000]\n",
            "[1980/5000]\n",
            "[1990/5000]\n",
            "[2000/5000]\n",
            "[2010/5000]\n",
            "[2020/5000]\n",
            "[2030/5000]\n",
            "[2040/5000]\n",
            "[2050/5000]\n",
            "[2060/5000]\n",
            "[2070/5000]\n",
            "[2080/5000]\n",
            "[2090/5000]\n",
            "[2100/5000]\n",
            "[2110/5000]\n",
            "[2120/5000]\n",
            "[2130/5000]\n",
            "[2140/5000]\n",
            "[2150/5000]\n",
            "[2160/5000]\n",
            "[2170/5000]\n",
            "[2180/5000]\n",
            "[2190/5000]\n",
            "[2200/5000]\n",
            "[2210/5000]\n",
            "[2220/5000]\n",
            "[2230/5000]\n",
            "[2240/5000]\n",
            "[2250/5000]\n",
            "[2260/5000]\n",
            "[2270/5000]\n",
            "[2280/5000]\n",
            "[2290/5000]\n",
            "[2300/5000]\n",
            "[2310/5000]\n",
            "[2320/5000]\n",
            "[2330/5000]\n",
            "[2340/5000]\n",
            "[2350/5000]\n",
            "[2360/5000]\n",
            "[2370/5000]\n",
            "[2380/5000]\n",
            "[2390/5000]\n",
            "[2400/5000]\n",
            "[2410/5000]\n",
            "[2420/5000]\n",
            "[2430/5000]\n",
            "[2440/5000]\n",
            "[2450/5000]\n",
            "[2460/5000]\n",
            "[2470/5000]\n",
            "[2480/5000]\n",
            "[2490/5000]\n",
            "[2500/5000]\n",
            "[2510/5000]\n",
            "[2520/5000]\n",
            "[2530/5000]\n",
            "[2540/5000]\n",
            "[2550/5000]\n",
            "[2560/5000]\n",
            "[2570/5000]\n",
            "[2580/5000]\n",
            "[2590/5000]\n",
            "[2600/5000]\n",
            "[2610/5000]\n",
            "[2620/5000]\n",
            "[2630/5000]\n",
            "[2640/5000]\n",
            "[2650/5000]\n",
            "[2660/5000]\n",
            "[2670/5000]\n",
            "[2680/5000]\n",
            "[2690/5000]\n",
            "[2700/5000]\n",
            "[2710/5000]\n",
            "[2720/5000]\n",
            "[2730/5000]\n",
            "[2740/5000]\n",
            "[2750/5000]\n",
            "[2760/5000]\n",
            "[2770/5000]\n",
            "[2780/5000]\n",
            "[2790/5000]\n",
            "[2800/5000]\n",
            "[2810/5000]\n",
            "[2820/5000]\n",
            "[2830/5000]\n",
            "[2840/5000]\n",
            "[2850/5000]\n",
            "[2860/5000]\n",
            "[2870/5000]\n",
            "[2880/5000]\n",
            "[2890/5000]\n",
            "[2900/5000]\n",
            "[2910/5000]\n",
            "[2920/5000]\n",
            "[2930/5000]\n",
            "[2940/5000]\n",
            "[2950/5000]\n",
            "[2960/5000]\n",
            "[2970/5000]\n",
            "[2980/5000]\n",
            "[2990/5000]\n",
            "[3000/5000]\n",
            "[3010/5000]\n",
            "[3020/5000]\n",
            "[3030/5000]\n",
            "[3040/5000]\n",
            "[3050/5000]\n",
            "[3060/5000]\n",
            "[3070/5000]\n",
            "[3080/5000]\n",
            "[3090/5000]\n",
            "[3100/5000]\n",
            "[3110/5000]\n",
            "[3120/5000]\n",
            "[3130/5000]\n",
            "[3140/5000]\n",
            "[3150/5000]\n",
            "[3160/5000]\n",
            "[3170/5000]\n",
            "[3180/5000]\n",
            "[3190/5000]\n",
            "[3200/5000]\n",
            "[3210/5000]\n",
            "[3220/5000]\n",
            "[3230/5000]\n",
            "[3240/5000]\n",
            "[3250/5000]\n",
            "[3260/5000]\n",
            "[3270/5000]\n",
            "[3280/5000]\n",
            "[3290/5000]\n",
            "[3300/5000]\n",
            "[3310/5000]\n",
            "[3320/5000]\n",
            "[3330/5000]\n",
            "[3340/5000]\n",
            "[3350/5000]\n",
            "[3360/5000]\n",
            "[3370/5000]\n",
            "[3380/5000]\n",
            "[3390/5000]\n",
            "[3400/5000]\n",
            "[3410/5000]\n",
            "[3420/5000]\n",
            "[3430/5000]\n",
            "[3440/5000]\n",
            "[3450/5000]\n",
            "[3460/5000]\n",
            "[3470/5000]\n",
            "[3480/5000]\n",
            "[3490/5000]\n",
            "[3500/5000]\n",
            "[3510/5000]\n",
            "[3520/5000]\n",
            "[3530/5000]\n",
            "[3540/5000]\n",
            "[3550/5000]\n",
            "[3560/5000]\n",
            "[3570/5000]\n",
            "[3580/5000]\n",
            "[3590/5000]\n",
            "[3600/5000]\n",
            "[3610/5000]\n",
            "[3620/5000]\n",
            "[3630/5000]\n",
            "[3640/5000]\n",
            "[3650/5000]\n",
            "[3660/5000]\n",
            "[3670/5000]\n",
            "[3680/5000]\n",
            "[3690/5000]\n",
            "[3700/5000]\n",
            "[3710/5000]\n",
            "[3720/5000]\n",
            "[3730/5000]\n",
            "[3740/5000]\n",
            "[3750/5000]\n",
            "[3760/5000]\n",
            "[3770/5000]\n",
            "[3780/5000]\n",
            "[3790/5000]\n",
            "[3800/5000]\n",
            "[3810/5000]\n",
            "[3820/5000]\n",
            "[3830/5000]\n",
            "[3840/5000]\n",
            "[3850/5000]\n",
            "[3860/5000]\n",
            "[3870/5000]\n",
            "[3880/5000]\n",
            "[3890/5000]\n",
            "[3900/5000]\n",
            "[3910/5000]\n",
            "[3920/5000]\n",
            "[3930/5000]\n",
            "[3940/5000]\n",
            "[3950/5000]\n",
            "[3960/5000]\n",
            "[3970/5000]\n",
            "[3980/5000]\n",
            "[3990/5000]\n",
            "[4000/5000]\n",
            "[4010/5000]\n",
            "[4020/5000]\n",
            "[4030/5000]\n",
            "[4040/5000]\n",
            "[4050/5000]\n",
            "[4060/5000]\n",
            "[4070/5000]\n",
            "[4080/5000]\n",
            "[4090/5000]\n",
            "[4100/5000]\n",
            "[4110/5000]\n",
            "[4120/5000]\n",
            "[4130/5000]\n",
            "[4140/5000]\n",
            "[4150/5000]\n",
            "[4160/5000]\n",
            "[4170/5000]\n",
            "[4180/5000]\n",
            "[4190/5000]\n",
            "[4200/5000]\n",
            "[4210/5000]\n",
            "[4220/5000]\n",
            "[4230/5000]\n",
            "[4240/5000]\n",
            "[4250/5000]\n",
            "[4260/5000]\n",
            "[4270/5000]\n",
            "[4280/5000]\n",
            "[4290/5000]\n",
            "[4300/5000]\n",
            "[4310/5000]\n",
            "[4320/5000]\n",
            "[4330/5000]\n",
            "[4340/5000]\n",
            "[4350/5000]\n",
            "[4360/5000]\n",
            "[4370/5000]\n",
            "[4380/5000]\n",
            "[4390/5000]\n",
            "[4400/5000]\n",
            "[4410/5000]\n",
            "[4420/5000]\n",
            "[4430/5000]\n",
            "[4440/5000]\n",
            "[4450/5000]\n",
            "[4460/5000]\n",
            "[4470/5000]\n",
            "[4480/5000]\n",
            "[4490/5000]\n",
            "[4500/5000]\n",
            "[4510/5000]\n",
            "[4520/5000]\n",
            "[4530/5000]\n",
            "[4540/5000]\n",
            "[4550/5000]\n",
            "[4560/5000]\n",
            "[4570/5000]\n",
            "[4580/5000]\n",
            "[4590/5000]\n",
            "[4600/5000]\n",
            "[4610/5000]\n",
            "[4620/5000]\n",
            "[4630/5000]\n",
            "[4640/5000]\n",
            "[4650/5000]\n",
            "[4660/5000]\n",
            "[4670/5000]\n",
            "[4680/5000]\n",
            "[4690/5000]\n",
            "[4700/5000]\n",
            "[4710/5000]\n",
            "[4720/5000]\n",
            "[4730/5000]\n",
            "[4740/5000]\n",
            "[4750/5000]\n",
            "[4760/5000]\n",
            "[4770/5000]\n",
            "[4780/5000]\n",
            "[4790/5000]\n",
            "[4800/5000]\n",
            "[4810/5000]\n",
            "[4820/5000]\n",
            "[4830/5000]\n",
            "[4840/5000]\n",
            "[4850/5000]\n",
            "[4860/5000]\n",
            "[4870/5000]\n",
            "[4880/5000]\n",
            "[4890/5000]\n",
            "[4900/5000]\n",
            "[4910/5000]\n",
            "[4920/5000]\n",
            "[4930/5000]\n",
            "[4940/5000]\n",
            "[4950/5000]\n",
            "[4960/5000]\n",
            "[4970/5000]\n",
            "[4980/5000]\n",
            "[4990/5000]\n",
            "[5000/5000]\n"
          ]
        }
      ],
      "source": [
        "# test to check if the whole dataset is read correctly\n",
        "images = read_all_images(DATA_PATH)\n",
        "print(images.shape)\n",
        "\n",
        "labels = read_labels(LABEL_PATH)\n",
        "print(labels.shape)\n",
        "\n",
        "# save images to disk\n",
        "save_images(images, labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "hI71lUwEIGtI",
        "o-136eJ5Eo3r",
        "wkif8gdZghz6"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "59bc8e2c397f0f3dd4c3f46a78ceb843605bec637a61d7dfe6aa303fd84548fe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
